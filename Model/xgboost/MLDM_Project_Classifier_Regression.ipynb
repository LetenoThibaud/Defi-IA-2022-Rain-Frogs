{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLDM Project Classifier/Regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PstDU6CqauyJ",
        "outputId": "760fbae4-ce87-4409-f92e-dd96340b63e9"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost \n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from xgboost import XGBRegressor, XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from time import time\n",
        "from google.colab import drive\n",
        "from time import perf_counter\n",
        "import xgboost as xgb\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess"
      ],
      "metadata": {
        "id": "yEJ_3hlwKreR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfsyQG7Ca_Fb",
        "outputId": "ab50b352-fcf5-45b5-da74-ed8d338a7866"
      },
      "source": [
        "# Dataset with deletion of NaN\n",
        "df_clean =  pd.read_csv('/gdrive/MyDrive/X_station_train_clean.csv', index_col=0)\n",
        "\n",
        "# Dataset with imputation of NaN \n",
        "# df_imputation = pd.read_csv('/gdrive/MyDrive/X_station_Train_imputation.csv', index_col=0)\n",
        "\n",
        "# 1rst Dataset with NaN\n",
        "df_full_dataset = pd.read_csv('/gdrive/MyDrive/X_station_train.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def m_mape(y_true,y_predict):\n",
        "    n = len(y_true)\n",
        "    At = np.array(y_true) + 1\n",
        "    Ft = np.array(y_predict) + 1\n",
        "\n",
        "    res = ((100/n)*(np.sum(np.abs((Ft-At)/At))))\n",
        "    return res"
      ],
      "metadata": {
        "id": "ZiWRit8d5FlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yS9YNKWUhk2T",
        "outputId": "8333ecab-caf0-4747-ea0c-412c0a235f05"
      },
      "source": [
        "# display(df_clean[df_clean['precipitations']>0])\n",
        "X_station = df_clean.copy()\n",
        "Y_station_train_regr = X_station.groupby(['station_id'])['precipitations'].shift(-1)\n",
        "X_station.loc[X_station.precipitations>0,'precipitations']=1\n",
        "print(X_station.shape)\n",
        "Y_station_train = X_station.groupby(['station_id'])['precipitations'].shift(-1)\n",
        "\n",
        "\n",
        "listNan=Y_station_train[Y_station_train.isna()].index.values.tolist()\n",
        "if len(listNan)>0:\n",
        "  X_station = X_station.drop(listNan)\n",
        "  Y_station_train = Y_station_train.drop(listNan)\n",
        "  Y_station_train_regr = Y_station_train_regr.drop(listNan)\n",
        "\n",
        "\n",
        "X_train = X_station[X_station['year']==2016]\n",
        "listX_train=X_station[X_station['year']==2016].index.values.tolist()\n",
        "y_train=Y_station_train[listX_train]\n",
        "y_train_regr = Y_station_train_regr[listX_train]\n",
        "\n",
        "X_test = X_station[X_station['year']==2017]\n",
        "listX_test=X_station[X_station['year']==2017].index.values.tolist()\n",
        "y_test=Y_station_train[listX_test]\n",
        "y_test_regr = Y_station_train_regr[listX_test]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2264105, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalizing_data (X, L_labels, L_labels_cos_sin, min_train, max_train):\n",
        "\n",
        "    # Exctact & Reorder columns\n",
        "    X = X[L_labels]\n",
        "\n",
        "    # Normalize\n",
        "    X = (X - min_train) / (max_train - min_train)\n",
        "\n",
        "    # Les valeurs sont normalisées entre 0 et 1, or cos(0)=cos(2*pi) => janvier=decembre, donc la plus grande valeur (normalisée) ne doit pas être 1\n",
        "    X['month_cos'] = np.cos(2*np.pi * X['month'] * 11/12)  \n",
        "    X['month_sin'] = np.sin(2*np.pi * X['month'] * 11/12)\n",
        "    X['hour_cos'] = np.cos(2*np.pi * X['hour'] * 23/24)\n",
        "    X['hour_sin'] = np.sin(2*np.pi * X['hour'] * 23/24)\n",
        "    X['wind_direction_cos'] = np.cos(2*np.pi * X['wind_direction'] * 359/360)\n",
        "    X['wind_direction_sin'] = np.sin(2*np.pi * X['wind_direction'] * 359/360)\n",
        "\n",
        "    X.drop('month', axis=1, inplace=True)\n",
        "    X.drop('hour', axis=1, inplace=True)\n",
        "    X.drop('wind_direction', axis=1, inplace=True)\n",
        "\n",
        "    # Reorder columns\n",
        "    X = X[L_labels_cos_sin]\n",
        "\n",
        "    # X_station = X_station.reset_index(drop=True)\n",
        "\n",
        "    return X"
      ],
      "metadata": {
        "id": "a3y4qyu_qwio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nM_HitXcjjc"
      },
      "source": [
        "# Resampling Dataset : remove "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApyoH_Tyve6h"
      },
      "source": [
        "def imalanced_remove_data(X_train,y_train):\n",
        "  df_class_0 = X_train[X_train['precipitations'] == 0]\n",
        "\n",
        "  df_class_1 = X_train[X_train['precipitations'] == 1]\n",
        "  display(len(df_class_0), len(df_class_1))\n",
        "\n",
        "  df_class_0_under = df_class_0.sample(len(df_class_1))\n",
        "\n",
        "\n",
        "  X_train_class = pd.concat([df_class_0_under, df_class_1], axis=0)\n",
        "\n",
        "  y_train_class = y_train[X_train_class.index]\n",
        "\n",
        "  print('Random under-sampling:')\n",
        "\n",
        "  return X_train_class,y_train_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu5nYpBBch44"
      },
      "source": [
        "X_train_balanced,y_train_balanced = imalanced_remove_data(X_train,y_train)\n",
        "print(X_train_balanced.shape,y_train_balanced.shape)\n",
        "\n",
        "check_for_nan = X_train_balanced.isnull().sum().sum()\n",
        "print(\"Xtrain nan :\",check_for_nan)\n",
        "check_for_nan = y_train_balanced.isnull().sum().sum()\n",
        "print(\"ytrain nan :\",check_for_nan)\n",
        "\n",
        "display(X_train_balanced[\"precipitations\"].unique())\n",
        "\n",
        " #Normalize\n",
        "L_labels = ['latitude', 'longitude', 'altitude', 'month', 'hour', 'wind_direction', 'wind_speed', 'temperature', 'humidity', 'dew_point', 'precipitations']\n",
        "L_labels_cos_sin = ['latitude', 'longitude', 'altitude', 'month_cos', 'month_sin', 'hour_cos', 'hour_sin', 'wind_direction_cos', 'wind_direction_sin', 'wind_speed', 'temperature', 'humidity', 'dew_point', 'precipitations']\n",
        "\n",
        "min_train = X_train[L_labels].min()\n",
        "max_train = X_train[L_labels].max()\n",
        "\n",
        "X_train_balanced = normalizing_data(X_train_balanced, L_labels, L_labels_cos_sin, min_train, max_train)\n",
        "X_test_norm = X_test\n",
        "X_test_norm = normalizing_data(X_test, L_labels, L_labels_cos_sin, min_train, max_train)\n",
        "# display(X_train_balanced)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classifier"
      ],
      "metadata": {
        "id": "CsI515CSM3dj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_classifier =xgb.XGBClassifier(\n",
        "    max_depth=5,\n",
        "    learning_rate=0.01,\n",
        "    gamma=0.25,\n",
        "    reg_lambda=1,\n",
        ")\n",
        "\n",
        "t1_start = perf_counter()              \n",
        "my_classifier.fit(X_train_balanced, y_train_balanced)\n",
        "t1_stop = perf_counter()\n",
        "print(\"Time:\", t1_stop-t1_start)"
      ],
      "metadata": {
        "id": "1nc5NGnu1Vys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_norm.reset_index(drop=True, inplace=True)\n",
        "t1_start = perf_counter() \n",
        "y_predict = my_classifier.predict(X_test_norm)\n",
        "t1_stop = perf_counter()\n",
        "print(\"Time:\", t1_stop-t1_start)\n",
        "print(\"My MAPE =\", m_mape(y_test,y_predict))\n",
        "print(\"MSE =\",mean_squared_error(y_test,y_predict))\n",
        "save = y_predict\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_predict)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "metadata": {
        "id": "UXnoFmmK1mA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regressor"
      ],
      "metadata": {
        "id": "H57jKmv8M8Ne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pluie = y_test_regr[y_predict == 1]\n",
        "\n",
        "id = np.where(y_predict == 1)[0].tolist()\n",
        "print(id)\n",
        "X_pluie = X_test_norm.loc[id]\n",
        "\n",
        "print(X_pluie.shape,y_pluie.shape)\n",
        "X_train_pluie, X_test_pluie, y_train_pluie, y_test_pluie = train_test_split(X_pluie, y_pluie, test_size=0.33, random_state=42)\n",
        "\n",
        "regr = xgb.XGBRegressor(n_estimators=20, \n",
        "                     max_depth=18,\n",
        "                     gamma=3.430739184133814, \n",
        "                     min_child_weight = 8,\n",
        "                     reg_alpha=180,\n",
        "                     reg_lambda=0.7436396623675846,\n",
        "                     random_state=123)\n",
        "\n",
        "t1_start = perf_counter()              \n",
        "regr.fit(X_train_pluie, y_train_pluie)\n",
        "t1_stop = perf_counter()\n",
        "print(\"Time:\", t1_stop-t1_start)\n",
        "\n"
      ],
      "metadata": {
        "id": "_wU1l8Gi2WgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t1_start = perf_counter() \n",
        "y_predict_regressor = regr.predict(X_test_pluie)\n",
        "t1_stop = perf_counter()\n",
        "\n",
        "print(y_test_pluie.shape,y_predict_regressor.shape)\n",
        "print(\"Time:\", t1_stop-t1_start)\n",
        "\n",
        "print(\"\\nMAPE données juste pluie\")\n",
        "print(\"My MAPE =\", m_mape(y_test_pluie,y_predict_regressor))\n",
        "print(\"MSE =\",mean_squared_error(y_test_pluie,y_predict_regressor))\n",
        "\n",
        "\n",
        "for i,j in zip(id,y_predict_regressor) :\n",
        "  y_predict[i]=j\n",
        "\n",
        "print(\"\\nMAPE toutes données\")\n",
        "print(\"My MAPE =\", m_mape(y_test_regr,y_predict))\n",
        "print(\"MSE =\",mean_squared_error(y_test_regr,y_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngvERRqW5Jel",
        "outputId": "79150a18-f001-4d16-82b8-e924fe39a08d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(21282,) (21282,)\n",
            "Time: 0.03510145299969736\n",
            "\n",
            "MAPE données juste pluie\n",
            "My MAPE = 39.09448333068498\n",
            "MSE = 1.2442115899833537\n",
            "\n",
            "MAPE toutes données\n",
            "My MAPE = 5.102892697277603\n",
            "MSE = 0.18847708241439076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(y_test_regr[y_test_regr>0])\n",
        "display(y_predict[y_predict>0])"
      ],
      "metadata": {
        "id": "pg4ky5qDi60H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data test\n"
      ],
      "metadata": {
        "id": "3stIex_95LX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_station_test_path = '/gdrive/MyDrive/X_station_test.csv'\n",
        "stations_coordinates_path = '/gdrive/MyDrive/stations_coordinates.csv'\n",
        "L_labels_test  = ['station_id', 'day_id', 'latitude', 'longitude', 'altitude',         'month',        'hour', 'wind_direction', 'wind_speed', 'temperature', 'humidity', 'dew_point', 'precipitations']\n",
        "X_station_test = preprocessing_X_station(X_station_test_path, stations_coordinates_path, L_labels_test)\n",
        "X_test = normalizing_data (X_station_test, L_labels, L_labels_cos_sin, min_train, max_train)\n",
        "display(X_test)"
      ],
      "metadata": {
        "id": "YHLSAZSE5R2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred_test1 = my_classifier.predict(X_test)\n",
        "id = np.where(Y_pred_test1 == 1)[0].tolist()\n",
        "X_pluie = X_test.loc[id]\n",
        "Y_pred_test2 = regr.predict(X_pluie)\n",
        "\n",
        "for i,j in zip(id,Y_pred_test2) :\n",
        "  Y_pred_test1[i]=j\n",
        "\n",
        "\n",
        "Y_pred_test1 = Y_pred_test1 * (max_train['precipitations'] - min_train['precipitations']) + min_train['precipitations']\n",
        "pred_merged = pd.concat([X_station_test, pd.DataFrame(Y_pred_test1, columns=['Y_pred'])], axis=1)\n",
        "pred_merged = pred_merged[['station_id',\t'day_id', 'Y_pred']]\n",
        "pred_merged['station_day_id'] = pred_merged[['station_id', 'day_id']].astype(str).apply(lambda x: '_'.join(x), axis=1)\n",
        "\n",
        "pred_merged.drop(['station_id',\t'day_id'], axis=1, inplace=True)\n",
        "pred_merged = pred_merged[['station_day_id', 'Y_pred']]\n",
        "\n",
        "pred_merged = pred_merged.groupby('station_day_id').agg(np.sum).reset_index()\n",
        "\n",
        "baseline_obs = pd.read_csv('/gdrive/MyDrive/Baseline_observation_test.csv')\n",
        "baseline_obs.drop('Prediction', axis=1, inplace=True)\n",
        "\n",
        "baseline_obs = baseline_obs.rename(columns={\"Id\": \"station_day_id\"})\n",
        "pred_merged = pd.merge(baseline_obs, pred_merged, how='inner', on=['station_day_id'])\n",
        "\n",
        "pred_merged = pred_merged.rename(columns={'station_day_id': \"Id\", 'Y_pred':\"Prediction\"})\n",
        "\n",
        "display(pred_merged)"
      ],
      "metadata": {
        "id": "tEZRDRpNFEdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_merged.to_csv('/gdrive/MyDrive/MLDM-Prediction/xgboostClassifer_XgboostRegressor_data_normalisee2.csv',index=False)"
      ],
      "metadata": {
        "id": "42yLdMoFG-kv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(id))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMU0HquSJYCv",
        "outputId": "845973bb-b0ef-480d-c5b9-d8c1386ca774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46802\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pred_merged['Prediction'].describe())\n",
        "display(len(Y_pred_test1[Y_pred_test1>0]))\n",
        "display(len(Y_pred_test1[Y_pred_test1==0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "l8ENxU2EGoEs",
        "outputId": "1eb6db86-dd13-4882-a6b7-d4697e0349c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    85140.000000\n",
            "mean         0.507104\n",
            "std          1.507873\n",
            "min          0.000000\n",
            "25%          0.000000\n",
            "50%          0.000000\n",
            "75%          0.000000\n",
            "max         17.925201\n",
            "Name: Prediction, dtype: float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "46802"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "2258000"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}