{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLDM Project 1 per month.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "556v7RL1dUkU",
        "outputId": "aef3c929-1e78-4ec3-af43-99945b445cd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost \n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from xgboost import XGBRegressor, XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
        "\n",
        "from time import time\n",
        "from google.colab import drive\n",
        "from time import perf_counter\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset with deletion of NaN\n",
        "df_clean =  pd.read_csv('/gdrive/MyDrive/X_station_train_clean.csv', index_col=0)\n",
        "\n",
        "# Dataset with imputation of NaN \n",
        "df_imputation = pd.read_csv('/gdrive/MyDrive/X_station_Train_imputation.csv', index_col=0)\n",
        "\n",
        "# 1rst Dataset with NaN\n",
        "df_full_dataset = pd.read_csv('/gdrive/MyDrive/X_station_train.csv')\n",
        "\n",
        "path_station_coordinate='/gdrive/MyDrive/stations_coordinates.csv'\n",
        "path_df_imputation=\"/gdrive/MyDrive/X_station_Train_imputation_Richard.csv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDJqbYB_dfrk",
        "outputId": "9d948941-7d72-4bb8-ac4a-49216a8d8e7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing_X_station (X_station_path, stations_coordinates_path, L_labels):\n",
        "  \n",
        "  # Renaming of features and add stations coordinates\n",
        "\n",
        "    # Open Data\n",
        "    X_station = pd.read_csv(X_station_path)\n",
        "    stations_coordinates = pd.read_csv(stations_coordinates_path)\n",
        "\n",
        "    # Split Date\n",
        "    if 'X_station_train' in X_station_path:\n",
        "        X_station['year']  = X_station['date'].apply(lambda row: row[:4]).astype('int32')\n",
        "        X_station['month'] = X_station['date'].apply(lambda row: row[5:7]).astype('int32')\n",
        "        X_station['day']   = X_station['date'].apply(lambda row: row[8:10]).astype('int32')\n",
        "        X_station['hour']  = X_station['date'].apply(lambda row: row[11:13]).astype('int32')\n",
        "        X_station.drop(\"date\", axis='columns', inplace=True)\n",
        "\n",
        "    if 'X_station_test' in X_station_path:\n",
        "        X_station['number_sta'] = X_station['Id'].apply(lambda row: row.split('_')[0]).astype('int32')\n",
        "        X_station['day_id']     = X_station['Id'].apply(lambda row: row.split('_')[1]).astype('int32')\n",
        "        X_station['hour']       = X_station['Id'].apply(lambda row: row.split('_')[2]).astype('int32')\n",
        "\n",
        "\n",
        "    X_station.drop(\"Id\", axis='columns', inplace=True)\n",
        "\n",
        "\n",
        "    # Add Stations Coordinates\n",
        "    X_station = pd.merge(X_station, stations_coordinates, how='left', on='number_sta')\n",
        "\n",
        "    # Rename columns\n",
        "    X_station.rename(columns={'number_sta':\"station_id\", \n",
        "                                    'ff': \"wind_speed\", \n",
        "                                    't': \"temperature\", \n",
        "                                    'td':\"dew_point\", \n",
        "                                    'hu':\"humidity\", \n",
        "                                    'dd':\"wind_direction\", \n",
        "                                    'precip':\"precipitations\",\n",
        "                                    'lat':\"latitude\", \n",
        "                                    'lon':\"longitude\", \n",
        "                                    'height_sta':\"altitude\"}, inplace=True)\n",
        "\n",
        "    # Reorder columns\n",
        "    X_station = X_station[L_labels]\n",
        "\n",
        "    # Sort by station and date\n",
        "    if 'X_station_train' in X_station_path:\n",
        "        X_station = X_station.sort_values(by=['station_id','year', 'month', 'day', 'hour'])\n",
        "    if 'X_station_test' in X_station_path:\n",
        "        X_station = X_station.sort_values(by=['station_id', 'day_id', 'hour'])\n",
        "\n",
        "    X_station = X_station.reset_index(drop=True)\n",
        "\n",
        "    return X_station\n",
        "def normalizing_data (X, L_labels, L_labels_cos_sin, min_train, max_train):\n",
        "\n",
        "    # Exctact & Reorder columns\n",
        "    X = X[L_labels]\n",
        "\n",
        "    # Normalize\n",
        "    X = (X - min_train) / (max_train - min_train)\n",
        "\n",
        "    # Les valeurs sont normalisées entre 0 et 1, or cos(0)=cos(2*pi) => janvier=decembre, donc la plus grande valeur (normalisée) ne doit pas être 1\n",
        "    X['hour_cos'] = np.cos(2*np.pi * X['hour'] * 23/24)\n",
        "    X['hour_sin'] = np.sin(2*np.pi * X['hour'] * 23/24)\n",
        "    X['wind_direction_cos'] = np.cos(2*np.pi * X['wind_direction'] * 359/360)\n",
        "    X['wind_direction_sin'] = np.sin(2*np.pi * X['wind_direction'] * 359/360)\n",
        "    X.drop('hour', axis=1, inplace=True)\n",
        "    X.drop('wind_direction', axis=1, inplace=True)\n",
        "\n",
        "    # Reorder columns\n",
        "    X = X[L_labels_cos_sin]\n",
        "\n",
        "    # X_station = X_station.reset_index(drop=True)\n",
        "\n",
        "    return X\n",
        "\n",
        "def m_mape(y_true,y_predict):\n",
        "    n = len(y_true)\n",
        "    At = np.array(y_true) + 1\n",
        "    Ft = np.array(y_predict) + 1\n",
        "\n",
        "    res = ((100/n)*(np.sum(np.abs((Ft-At)/At))))\n",
        "    return res"
      ],
      "metadata": {
        "id": "eZlH6J3LdmIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_test_train_split(dataset):\n",
        "\n",
        "  Y_station_train = dataset.groupby(['station_id'])['precipitations'].shift(-1)\n",
        "  X_train_clean = dataset[[\"station_id\",\"latitude\",\"longitude\",\"altitude\",\"timestamp\",\"year\",\"month\",\"day\",\"hour\",\"wind_direction\",\"wind_speed\",\"temperature\",\"humidity\",\"dew_point\",\"precipitations\"]]\n",
        "  \n",
        "  Y_train_clean = X_train_clean.groupby(['station_id'])['precipitations'].shift(-1)\n",
        "  Y_train = df_full_dataset.groupby(['number_sta'])['precip'].shift(-1)\n",
        "  # Y_train_imputation=X_train_imputation.groupby(['station_id'])['precipitations'].shift(-1)\n",
        "\n",
        "  # Drop NaN\n",
        "\n",
        "  listNan=Y_train_clean[Y_train_clean.isna()].index.values.tolist()\n",
        "  if len(listNan)>0:\n",
        "    X_train_clean = X_train_clean.drop(listNan)\n",
        "    Y_train_clean = Y_train_clean.drop(listNan)\n",
        "\n",
        "  check_for_nan = X_train_clean.isnull().sum().sum()\n",
        "  print(\"Xtrain nan :\",check_for_nan)\n",
        "\n",
        "  check_for_nan = Y_train_clean.isnull().sum().sum()\n",
        "  print(\"y train nan\",check_for_nan)\n",
        "\n",
        "  X_train = X_train_clean[X_train_clean['year']==2016]\n",
        "  listX_train=X_train_clean[X_train_clean['year']==2016].index.values.tolist()\n",
        "  y_train=Y_train_clean[listX_train]\n",
        "\n",
        "  X_test = X_train_clean[X_train_clean['year']==2017]\n",
        "  listX_test=X_train_clean[X_train_clean['year']==2017].index.values.tolist()\n",
        "  y_test=Y_train_clean[listX_test]\n",
        "  return X_train,X_test,y_train,y_test\n",
        "\n",
        "def data_month(X,y):\n",
        "  jan_index = X[X[\"month\"]==1].index.values.tolist()\n",
        "  X_jan = X.loc[jan_index]\n",
        "  y_jan = y.loc[jan_index]\n",
        "\n",
        "  feb_index = X[X[\"month\"]==2].index.values.tolist()\n",
        "  X_feb = X.loc[feb_index]\n",
        "  y_feb = y.loc[feb_index]\n",
        "\n",
        "  march_index = X[X[\"month\"]==3].index.values.tolist()\n",
        "  X_march = X.loc[march_index]\n",
        "  y_march = y.loc[march_index]\n",
        "\n",
        "  apr_index = X[X[\"month\"]==4].index.values.tolist()\n",
        "  X_apr = X.loc[apr_index]\n",
        "  y_apr = y.loc[apr_index]\n",
        "\n",
        "  may_index = X[X[\"month\"]==5].index.values.tolist()\n",
        "  X_may = X.loc[may_index]\n",
        "  y_may = y.loc[may_index]\n",
        "\n",
        "  june_index = X[X[\"month\"]==6].index.values.tolist()\n",
        "  X_june = X.loc[june_index]\n",
        "  y_june = y.loc[june_index]\n",
        "\n",
        "  july_index = X[X[\"month\"]==7].index.values.tolist()\n",
        "  X_july = X.loc[july_index]\n",
        "  y_july = y.loc[july_index]\n",
        "\n",
        "  aug_index = X[X[\"month\"]==8].index.values.tolist()\n",
        "  X_aug = X.loc[aug_index]\n",
        "  y_aug = y.loc[aug_index]\n",
        "\n",
        "  sept_index = X[X[\"month\"]==9].index.values.tolist()\n",
        "  X_sept = X.loc[sept_index]\n",
        "  y_sept = y.loc[sept_index]\n",
        "\n",
        "  oct_index = X[X[\"month\"]==10].index.values.tolist()\n",
        "  X_oct = X.loc[oct_index]\n",
        "  y_oct = y.loc[oct_index]\n",
        "\n",
        "  nov_index = X[X[\"month\"]==11].index.values.tolist()\n",
        "  X_nov = X.loc[nov_index]\n",
        "  y_nov = y.loc[nov_index]\n",
        "\n",
        "  dec_index = X[X[\"month\"]==12].index.values.tolist()\n",
        "  X_dec = X.loc[dec_index]\n",
        "  y_dec = y.loc[dec_index]\n",
        "\n",
        "  X= X.drop('month', 1)\n",
        "  X_jan=X_jan.drop('month', 1)\n",
        "  X_feb=X_feb.drop('month', 1)\n",
        "  X_march=X_march.drop('month', 1)\n",
        "  X_apr=X_apr.drop('month', 1)\n",
        "  X_may=X_may.drop('month', 1)\n",
        "  X_june=X_june.drop('month', 1)\n",
        "  X_july=X_july.drop('month', 1)\n",
        "  X_sept=X_sept.drop('month', 1)\n",
        "  X_oct=X_oct.drop('month', 1)\n",
        "  X_nov=X_nov.drop('month', 1)\n",
        "  X_dec=X_dec.drop('month', 1)\n",
        "  return X,y,X_jan,y_jan,X_feb,y_feb,X_march,y_march,X_apr,y_apr,X_may,y_may,X_june,y_june,X_july,y_july,X_aug,y_aug,X_sept,y_sept,X_oct,y_oct,X_nov,y_nov,X_dec,y_dec\n",
        "\n",
        "\n",
        "def my_normalize_permonth(dataset,X_train,X_test,y_train,y_test):\n",
        "  #Normalize\n",
        "  Y_station_train = dataset.groupby(['station_id'])['precipitations'].shift(-1)\n",
        "\n",
        "  L_labels = ['latitude', 'longitude', 'altitude', 'hour', 'wind_direction', 'wind_speed', 'temperature', 'humidity', 'dew_point', 'precipitations']\n",
        "  L_labels_cos_sin = ['latitude', 'longitude', 'altitude', 'hour_cos', 'hour_sin', 'wind_direction_cos', 'wind_direction_sin', 'wind_speed', 'temperature', 'humidity', 'dew_point', 'precipitations']\n",
        "\n",
        "  min_train = X_train[L_labels].min()\n",
        "  max_train = X_train[L_labels].max()\n",
        "\n",
        "  X_train = normalizing_data (X_train, L_labels, L_labels_cos_sin, min_train, max_train)\n",
        "  X_test = normalizing_data (X_test, L_labels, L_labels_cos_sin, min_train, max_train)\n",
        "  \n",
        "  Y_temp = (Y_station_train - min_train['precipitations']) / (max_train['precipitations'] - min_train['precipitations'])\n",
        "  y_train, y_test = Y_temp.loc[X_train.index], Y_temp.loc[X_test.index]\n",
        "\n",
        "  print(\"train shape\",X_train.shape,y_train.shape)\n",
        "  print(\"test shape\",X_test.shape,y_test.shape)\n",
        "\n",
        "  return X_train,y_train,X_test,y_test"
      ],
      "metadata": {
        "id": "joLl6K3bdtdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test=my_test_train_split(df_clean)\n",
        "\n",
        "X_train,y_train,X_jan_train,y_jan_train,X_feb_train,y_feb_train,X_march_train,y_march_train,X_apr_train,y_apr_train,X_may_train,y_may_train,X_june_train,y_june_train,X_july_train,y_july_train,X_aug_train,y_aug_train,X_sept_train,y_sept_train,X_oct_train,y_oct_train,X_nov_train,y_nov_train,X_dec_train,y_dec_train = data_month(X_train,y_train)\n",
        "X_test,y_test,X_jan_test,y_jan_test,X_feb_test,y_feb_test,X_march_test,y_march_test,X_apr_test,y_apr_test,X_may_test,y_may_test,X_june_test,y_june_test,X_july_test,y_july_test,X_aug_test,y_aug_test,X_sept_test,y_sept_test,X_oct_test,y_oct_test,X_nov_test,y_nov_test,X_dec_test,y_dec_test = data_month(X_test,y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_H0kenRifBmz",
        "outputId": "6cda0ba3-b41c-45ce-ade4-3c8128f4b406"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Xtrain nan : 0\n",
            "y train nan 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_jan_train,y_jan_train,X_jan_test,y_jan_test=my_normalize_permonth(df_clean,X_jan_train,X_jan_test,y_jan_train,y_jan_test)\n",
        "X_feb_train,y_feb_train,X_feb_test,y_feb_test=my_normalize_permonth(df_clean,X_feb_train,X_feb_test,y_feb_train,y_feb_test)\n",
        "X_march_train,y_march_train,X_march_test,y_march_test=my_normalize_permonth(df_clean,X_march_train,X_march_test,y_march_train,y_march_test)\n",
        "X_apr_train,y_apr_train,X_apr_test,y_apr_test=my_normalize_permonth(df_clean,X_apr_train,X_apr_test,y_apr_train,y_apr_test)\n",
        "X_may_train,y_may_train,X_may_test,y_may_test=my_normalize_permonth(df_clean,X_may_train,X_may_test,y_may_train,y_may_test)\n",
        "X_june_train,y_june_train,X_june_test,y_june_test=my_normalize_permonth(df_clean,X_june_train,X_june_test,y_june_train,y_june_test)\n",
        "X_july_train,y_july_train,X_july_test,y_july_test=my_normalize_permonth(df_clean,X_july_train,X_july_test,y_july_train,y_july_test)\n",
        "X_aug_train,y_aug_train,X_aug_test,y_aug_test=my_normalize_permonth(df_clean,X_aug_train,X_aug_test,y_aug_train,y_aug_test)\n",
        "X_sept_train,y_sept_train,X_sept_test,y_sept_test=my_normalize_permonth(df_clean,X_sept_train,X_sept_test,y_sept_train,y_sept_test)\n",
        "X_oct_train,y_oct_train,X_oct_test,y_oct_test=my_normalize_permonth(df_clean,X_oct_train,X_oct_test,y_oct_train,y_oct_test)\n",
        "X_nov_train,y_nov_train,X_nov_test,y_nov_test=my_normalize_permonth(df_clean,X_nov_train,X_nov_test,y_nov_train,y_nov_test)\n",
        "X_dec_train,y_dec_train,X_dec_test,y_dec_test=my_normalize_permonth(df_clean,X_dec_train,X_dec_test,y_dec_train,y_dec_test)"
      ],
      "metadata": {
        "id": "a9KJKBPilsXP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1d7fcaf-5bb1-445c-af4b-23cfcf779795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train shape (91865, 12) (91865,)\n",
            "test shape (97951, 12) (97951,)\n",
            "train shape (85674, 12) (85674,)\n",
            "test shape (89458, 12) (89458,)\n",
            "train shape (93240, 12) (93240,)\n",
            "test shape (98865, 12) (98865,)\n",
            "train shape (89675, 12) (89675,)\n",
            "test shape (96106, 12) (96106,)\n",
            "train shape (89102, 12) (89102,)\n",
            "test shape (98604, 12) (98604,)\n",
            "train shape (89798, 12) (89798,)\n",
            "test shape (93571, 12) (93571,)\n",
            "train shape (93656, 12) (93656,)\n",
            "test shape (97777, 12) (97777,)\n",
            "train shape (95081, 12) (95081,)\n",
            "test shape (99275, 12) (99275,)\n",
            "train shape (92020, 12) (92020,)\n",
            "test shape (94920, 12) (94920,)\n",
            "train shape (96296, 12) (96296,)\n",
            "test shape (98829, 12) (98829,)\n",
            "train shape (94435, 12) (94435,)\n",
            "test shape (95186, 12) (95186,)\n",
            "train shape (97377, 12) (97377,)\n",
            "test shape (95204, 12) (95204,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_jan = XGBRegressor(n_estimators=500, max_depth=18, gamma=3.430739184133814, min_child_weight = 8,reg_alpha=180, reg_lambda=0.7436396623675846, random_state=123)\n",
        "t1_start = perf_counter()\n",
        "model_jan.fit(X_jan_train,y_jan_train)\n",
        "t1_stop = perf_counter()\n",
        "# print(\"Time_jan:\", t1_stop-t1_start)\n",
        "\n",
        "model_feb = XGBRegressor(n_estimators=500, max_depth=18, gamma=3.430739184133814, min_child_weight = 8,reg_alpha=180, reg_lambda=0.7436396623675846, random_state=123)\n",
        "t1_start = perf_counter()              \n",
        "model_feb.fit(X_feb_train,y_feb_train)\n",
        "t1_stop = perf_counter()\n",
        "# print(\"Time_jan:\", t1_stop-t1_start)\n",
        "\n",
        "model_march = XGBRegressor(n_estimators=500, max_depth=18, gamma=3.430739184133814, min_child_weight = 8,reg_alpha=180, reg_lambda=0.7436396623675846, random_state=123)\n",
        "t1_start = perf_counter()              \n",
        "model_march.fit(X_march_train,y_march_train)\n",
        "t1_stop = perf_counter()\n",
        "\n",
        "model_apr = XGBRegressor(n_estimators=500, max_depth=18, gamma=3.430739184133814, min_child_weight = 8,reg_alpha=180, reg_lambda=0.7436396623675846, random_state=123)\n",
        "t1_start = perf_counter()              \n",
        "model_apr.fit(X_apr_train,y_apr_train)\n",
        "t1_stop = perf_counter()\n",
        "\n",
        "model_may = XGBRegressor(n_estimators=500, max_depth=18, gamma=3.430739184133814, min_child_weight = 8,reg_alpha=180, reg_lambda=0.7436396623675846, random_state=123)\n",
        "t1_start = perf_counter()              \n",
        "model_may.fit(X_may_train,y_may_train)\n",
        "t1_stop = perf_counter()\n",
        "\n",
        "model_june = XGBRegressor(n_estimators=500, max_depth=18, gamma=3.430739184133814, min_child_weight = 8,reg_alpha=180, reg_lambda=0.7436396623675846, random_state=123)\n",
        "t1_start = perf_counter()              \n",
        "model_june.fit(X_june_train,y_june_train)\n",
        "t1_stop = perf_counter()\n",
        "\n",
        "model_july = XGBRegressor(n_estimators=500, max_depth=18, gamma=3.430739184133814, min_child_weight = 8,reg_alpha=180, reg_lambda=0.7436396623675846, random_state=123)\n",
        "t1_start = perf_counter()              \n",
        "model_july.fit(X_july_train,y_july_train)\n",
        "t1_stop = perf_counter()\n",
        "\n",
        "model_aug = XGBRegressor(n_estimators=500, max_depth=18, gamma=3.430739184133814, min_child_weight = 8,reg_alpha=180, reg_lambda=0.7436396623675846, random_state=123)\n",
        "t1_start = perf_counter()              \n",
        "model_aug.fit(X_aug_train,y_aug_train)\n",
        "t1_stop = perf_counter()\n",
        "\n",
        "model_sept = XGBRegressor(n_estimators=500, max_depth=18, gamma=3.430739184133814, min_child_weight = 8,reg_alpha=180, reg_lambda=0.7436396623675846, random_state=123)\n",
        "t1_start = perf_counter()              \n",
        "model_sept.fit(X_sept_train,y_sept_train)\n",
        "t1_stop = perf_counter()\n",
        "\n",
        "model_oct = XGBRegressor(n_estimators=500, max_depth=18, gamma=3.430739184133814, min_child_weight = 8,reg_alpha=180, reg_lambda=0.7436396623675846, random_state=123)\n",
        "t1_start = perf_counter()              \n",
        "model_oct.fit(X_oct_train,y_oct_train)\n",
        "t1_stop = perf_counter()\n",
        "\n",
        "model_nov = XGBRegressor(n_estimators=500, max_depth=18, gamma=3.430739184133814, min_child_weight = 8,reg_alpha=180, reg_lambda=0.7436396623675846, random_state=123)\n",
        "t1_start = perf_counter()              \n",
        "model_nov.fit(X_nov_train,y_nov_train)\n",
        "t1_stop = perf_counter()\n",
        "\n",
        "model_dec = XGBRegressor(n_estimators=500, max_depth=18, gamma=3.430739184133814, min_child_weight = 8,reg_alpha=180, reg_lambda=0.7436396623675846, random_state=123)\n",
        "t1_start = perf_counter()              \n",
        "model_dec.fit(X_dec_train,y_dec_train)\n",
        "t1_stop = perf_counter()"
      ],
      "metadata": {
        "id": "ygg1HnPRqFn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict = model_jan.predict(X_jan_test)\n",
        "print(y_predict)\n",
        "print(type(y_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2PSfh7MF7Wk",
        "outputId": "c2fe7fc7-b1e6-4ee7-8a36-044a9e41a91a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.00994861 0.00994861 0.00994861 ... 0.00994861 0.00994861 0.00994861]\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict = model_jan.predict(X_jan_test)\n",
        "print(\"My MAPE =\", m_mape(y_jan_test,y_predict))\n",
        "print(\"MSE =\",mean_squared_error(y_jan_test,y_predict))\n",
        "\n",
        "y_predict = model_feb.predict(X_feb_test)\n",
        "print(\"My MAPE =\", m_mape(y_feb_test,y_predict))\n",
        "print(\"MSE =\",mean_squared_error(y_feb_test,y_predict))\n",
        "\n",
        "y_predict = model_march.predict(X_march_test)\n",
        "print(\"My MAPE =\", m_mape(y_march_test,y_predict))\n",
        "print(\"MSE =\",mean_squared_error(y_march_test,y_predict))\n",
        "\n",
        "y_predict = model_apr.predict(X_apr_test)\n",
        "print(\"My MAPE =\", m_mape(y_apr_test,y_predict))\n",
        "print(\"MSE =\",mean_squared_error(y_apr_test,y_predict))\n",
        "\n",
        "y_predict = model_may.predict(X_may_test)\n",
        "print(\"My MAPE =\", m_mape(y_may_test,y_predict))\n",
        "print(\"MSE =\",mean_squared_error(y_may_test,y_predict))\n",
        "\n",
        "y_predict = model_june.predict(X_june_test)\n",
        "print(\"My MAPE =\", m_mape(y_june_test,y_predict))\n",
        "print(\"MSE =\",mean_squared_error(y_june_test,y_predict))\n",
        "\n",
        "y_predict = model_july.predict(X_july_test)\n",
        "print(\"My MAPE =\", m_mape(y_july_test,y_predict))\n",
        "print(\"MSE =\",mean_squared_error(y_july_test,y_predict))\n",
        "\n",
        "y_predict = model_aug.predict(X_aug_test)\n",
        "print(\"My MAPE =\", m_mape(y_aug_test,y_predict))\n",
        "print(\"MSE =\",mean_squared_error(y_aug_test,y_predict))\n",
        "\n",
        "y_predict = model_sept.predict(X_sept_test)\n",
        "print(\"My MAPE =\", m_mape(y_sept_test,y_predict))\n",
        "print(\"MSE =\",mean_squared_error(y_sept_test,y_predict))\n",
        "\n",
        "y_predict = model_oct.predict(X_oct_test)\n",
        "print(\"My MAPE =\", m_mape(y_oct_test,y_predict))\n",
        "print(\"MSE =\",mean_squared_error(y_oct_test,y_predict))\n",
        "\n",
        "y_predict = model_nov.predict(X_nov_test)\n",
        "print(\"My MAPE =\", m_mape(y_nov_test,y_predict))\n",
        "print(\"MSE =\",mean_squared_error(y_nov_test,y_predict))\n",
        "\n",
        "y_predict = model_dec.predict(X_dec_test)\n",
        "print(\"My MAPE =\", m_mape(y_dec_test,y_predict))\n",
        "print(\"MSE =\",mean_squared_error(y_dec_test,y_predict))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm_d6wbPrxm1",
        "outputId": "b263da07-baa0-4f3b-f0c4-f2b148c53e94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My MAPE = 1.2570294869521748\n",
            "MSE = 0.00042274620458173767\n",
            "My MAPE = 0.926970277830805\n",
            "MSE = 0.0003013558363974034\n",
            "My MAPE = 1.1789457213575596\n",
            "MSE = 0.0007105927079665449\n",
            "My MAPE = 0.5017051274614899\n",
            "MSE = 9.198437333299878e-05\n",
            "My MAPE = 0.558056893488985\n",
            "MSE = 0.0001516277866899749\n",
            "My MAPE = 0.5740071298433448\n",
            "MSE = 0.00021945166483971522\n",
            "My MAPE = 0.5579504989122119\n",
            "MSE = 0.0009818321713234077\n",
            "My MAPE = 0.5150552784087876\n",
            "MSE = 0.00037961683095759857\n",
            "My MAPE = 0.6116290131676222\n",
            "MSE = 0.0003082504092785334\n",
            "My MAPE = 0.5450245536826063\n",
            "MSE = 0.00015861006964890427\n",
            "My MAPE = 0.9744732762222601\n",
            "MSE = 0.0004471085848175082\n",
            "My MAPE = 1.263959865334934\n",
            "MSE = 0.0019084034607334919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_station_test_path = '/gdrive/MyDrive/X_station_test.csv'\n",
        "stations_coordinates_path = '/gdrive/MyDrive/stations_coordinates.csv'\n",
        "L_labels_test  = ['station_id', 'day_id', 'latitude', 'longitude', 'altitude','month','hour', 'wind_direction', 'wind_speed', 'temperature', 'humidity', 'dew_point', 'precipitations']\n",
        "X_station_test = preprocessing_X_station(X_station_test_path, stations_coordinates_path, L_labels_test)\n",
        "L_labels = ['latitude', 'longitude', 'altitude', 'hour', 'wind_direction', 'wind_speed', 'temperature', 'humidity', 'dew_point', 'precipitations']\n",
        "L_labels_cos_sin = ['latitude', 'longitude', 'altitude', 'hour_cos', 'hour_sin', 'wind_direction_cos', 'wind_direction_sin', 'wind_speed', 'temperature', 'humidity', 'dew_point', 'precipitations']\n",
        "min_train = X_train[L_labels].min()\n",
        "max_train = X_train[L_labels].max()\n",
        "X_test_norm = normalizing_data (X_station_test, L_labels, L_labels_cos_sin, min_train, max_train)\n",
        "# display(X_station_test)\n",
        "display(X_test_norm)\n",
        "display(X_dec_train)\n",
        "display(X_test_norm.loc[0])\n",
        "Y_pred_test=[]\n"
      ],
      "metadata": {
        "id": "UjAZ_YGKtnDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict = model_jan.predict(pd.DataFrame(X_test_norm.iloc[0]).T)[0]\n",
        "print(y_predict)\n",
        "print(type(y_predict))"
      ],
      "metadata": {
        "id": "Wxwzk0GyHqae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# secondrow = pd.DataFrame(X_test_norm.iloc[1]).T\n",
        "# y_predict = model_dec.predict(secondrow)\n",
        "\n",
        "for i in range(len(X_station_test)):\n",
        "  if X_station_test.loc[i][\"month\"] == 1:\n",
        "    y_predict = model_jan.predict(pd.DataFrame(X_test_norm.iloc[i]).T)[0]\n",
        "  elif X_station_test.loc[i][\"month\"] == 2:\n",
        "    y_predict = model_feb.predict(pd.DataFrame(X_test_norm.iloc[i]).T)[0]\n",
        "  elif X_station_test.loc[i][\"month\"] == 3:\n",
        "    y_predict = model_march.predict(pd.DataFrame(X_test_norm.iloc[i]).T)[0]\n",
        "  elif X_station_test.loc[i][\"month\"] == 4:\n",
        "    y_predict = model_apr.predict(pd.DataFrame(X_test_norm.iloc[i]).T)[0]\n",
        "  elif X_station_test.loc[i][\"month\"] == 5:\n",
        "    y_predict = model_may.predict(pd.DataFrame(X_test_norm.iloc[i]).T)[0]\n",
        "  elif X_station_test.loc[i][\"month\"] == 6:\n",
        "    y_predict = model_june.predict(pd.DataFrame(X_test_norm.iloc[i]).T)[0]\n",
        "  elif X_station_test.loc[i][\"month\"] == 7:\n",
        "    y_predict = model_july.predict(pd.DataFrame(X_test_norm.iloc[i]).T)[0]\n",
        "  elif X_station_test.loc[i][\"month\"] == 8:\n",
        "    y_predict = model_aug.predict(pd.DataFrame(X_test_norm.iloc[i]).T)[0]\n",
        "  elif X_station_test.loc[i][\"month\"] == 9:\n",
        "    y_predict = model_sept.predict(pd.DataFrame(X_test_norm.iloc[i]).T)[0]\n",
        "  elif X_station_test.loc[i][\"month\"] == 10:\n",
        "    y_predict = model_oct.predict(pd.DataFrame(X_test_norm.iloc[i]).T)[0]\n",
        "  elif X_station_test.loc[i][\"month\"] ==11:\n",
        "    y_predict = model_nov.predict(pd.DataFrame(X_test_norm.iloc[i]).T)[0]\n",
        "  elif X_station_test.loc[i][\"month\"] == 12:\n",
        "    y_predict = model_dec.predict(pd.DataFrame(X_test_norm.iloc[i]).T)[0]\n",
        "  Y_pred_test.append(y_predict)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uCLXQQadvoOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y_pred_test[:10])\n",
        "# Y_pred_test = Y_pred_test * (max_train['precipitations'] - min_train['precipitations']) + min_train['precipitations']\n",
        "print(X_station_test.shape)\n",
        "print(len(Y_pred_test))\n",
        "# display(Y_pred_test[0])\n",
        "save = Y_pred_test\n",
        "print(type(Y_pred_test))\n",
        "# Y_pred_test = np.array(Y_pred_test)\n",
        "pred_merged = pd.concat([X_station_test, pd.DataFrame(Y_pred_test, columns=['Y_pred'])], axis=1)\n",
        "\n",
        "pred_merged = pred_merged[['station_id',\t'day_id', 'Y_pred']]\n",
        "pred_merged['station_day_id'] = pred_merged[['station_id', 'day_id']].astype(str).apply(lambda x: '_'.join(x), axis=1)\n",
        "\n",
        "pred_merged.drop(['station_id',\t'day_id'], axis=1, inplace=True)\n",
        "pred_merged = pred_merged[['station_day_id', 'Y_pred']]\n",
        "\n",
        "\n",
        "pred_merged = pred_merged.groupby('station_day_id').agg(np.sum).reset_index()\n",
        "\n",
        "baseline_obs = pd.read_csv('/gdrive/MyDrive/Baseline_observation_test.csv')\n",
        "baseline_obs.drop('Prediction', axis=1, inplace=True)\n",
        "\n",
        "baseline_obs = baseline_obs.rename(columns={\"Id\": \"station_day_id\"})\n",
        "display(baseline_obs)\n",
        "display(pred_merged)\n",
        "pred_merged = pd.merge(baseline_obs, pred_merged, how='inner', on=['station_day_id'])\n",
        "display(pred_merged)\n",
        "pred_merged = pred_merged.rename(columns={'station_day_id': \"Id\", 'Y_pred':\"Prediction\"})\n",
        "\n",
        "display(pred_merged)"
      ],
      "metadata": {
        "id": "U5SgJuKLQA39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Y_pred_test = Y_pred_test * (max_train['precipitations'] - min_train['precipitations']) + min_train['precipitations']\n",
        "# print(X_station_test.shape)\n",
        "# print(Y_pred_test.shape)\n",
        "# display(Y_pred_test)\n",
        "\n",
        "pred_merged = pd.concat([X_station_test, pd.DataFrame(Y_pred_test, columns=['Y_pred'])], axis=1)\n",
        "pred_merged = pred_merged[['station_id',\t'day_id', 'Y_pred']]\n",
        "pred_merged['station_id'] = [str(item)[:-2] for item in pred_merged['station_id']]\n",
        "pred_merged['day_id'] = [str(item)[:-2] for item in pred_merged['day_id']]\n",
        "display(pred_merged)\n",
        "pred_merged['station_day_id'] = pred_merged[['station_id', 'day_id']].astype(str).apply(lambda x: '_'.join(x), axis=1)\n",
        "display(pred_merged[:30])\n",
        "\n",
        "pred_merged.drop(['station_id',\t'day_id'], axis=1, inplace=True)\n",
        "pred_merged = pred_merged[['station_day_id', 'Y_pred']]\n",
        "\n",
        "pred_merged = pred_merged.groupby('station_day_id').agg(np.sum).reset_index()\n",
        "\n",
        "baseline_obs = pd.read_csv('/gdrive/MyDrive/Baseline_observation_test.csv')\n",
        "baseline_obs.drop('Prediction', axis=1, inplace=True)\n",
        "\n",
        "baseline_obs = baseline_obs.rename(columns={\"Id\": \"station_day_id\"})\n",
        "pred_merged = pd.merge(baseline_obs, pred_merged, how='inner', on=['station_day_id'])\n",
        "\n",
        "pred_merged = pred_merged.rename(columns={'station_day_id': \"Id\", 'Y_pred':\"Prediction\"})\n",
        "\n",
        "display(pred_merged)"
      ],
      "metadata": {
        "id": "BwsQnaQ7lyCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(pred_merged.describe())\n",
        "# display(Y_pred_test)\n",
        "pred_merged.to_csv('/gdrive/MyDrive/MLDM-Prediction/xgboost_per_month_data_clean_normalisee.csv',index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "2lHdJfmJh6IP",
        "outputId": "e82667d1-0ef9-4d48-d40e-5028f485f1a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-eb0d83b5-2016-4482-bd3e-d4aec64e2bda\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>85140.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.130050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.049231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.073869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.094015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.108682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.163670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.619402</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb0d83b5-2016-4482-bd3e-d4aec64e2bda')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eb0d83b5-2016-4482-bd3e-d4aec64e2bda button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eb0d83b5-2016-4482-bd3e-d4aec64e2bda');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         Prediction\n",
              "count  85140.000000\n",
              "mean       0.130050\n",
              "std        0.049231\n",
              "min        0.073869\n",
              "25%        0.094015\n",
              "50%        0.108682\n",
              "75%        0.163670\n",
              "max        0.619402"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}