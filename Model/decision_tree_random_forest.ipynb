{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Hh7xbCohpQ0"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score, RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djtaMR0QMwCB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuWAUNF4izLP",
        "outputId": "b8fc4b59-e864-49d0-f655-31f0206f13e6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h14zAj01htdn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56767308-27c1-4f7e-b805-9989acda5290"
      },
      "source": [
        "x_train = pd.read_csv('/content/drive/MyDrive/weather_data/X_station_coord_2nn_imputed_by_day.csv')\n",
        "y_train = x_train['ground_truth']\n",
        "del x_train['ground_truth']\n",
        "del x_train['date']\n",
        "del x_train['timestamp']\n",
        "del x_train['number_sta']\n",
        "del x_train['Id']\n",
        "\n",
        "print(x_train.shape)\n",
        "\n",
        "\n",
        "x_test = pd.read_csv('/content/drive/MyDrive/weather_data/X_test_coord_2nn_imputed_by_day.csv')\n",
        "test_ids = x_test['Id']\n",
        "del x_test['Id']\n",
        "del x_test['number_sta']\n",
        "print(x_test.shape)\n",
        "\n",
        "seed = 1998"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(172374, 10)\n",
            "(96055, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sg9nQLOwf6vo"
      },
      "source": [
        "## Decision tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSWFwoicGSQp"
      },
      "source": [
        "def cross_validation_decision_tree(x, y, cv_type, n_random_test=10):\n",
        "    \"\"\"\n",
        "    :param x_train:\n",
        "    :param y_train:\n",
        "    :param cv_type: must be 'random' or 'gridsearch'\n",
        "    :param n_random_test: nombre de jeux de paramètres à tester\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    params_to_tune = {'max_depth' : [5, 10, 20, 50],\n",
        "                      'max_features' : [4, 6, 8, 10, np.sqrt(x.shape[1])],\n",
        "                      'min_samples_leaf' : [10, 100, 500, 1000]\n",
        "                      }\n",
        "    # split the dataset by keeping 10% of the dataset for train and 5% for testing during the CV\n",
        "    x_cv, _, y_cv, _ = train_test_split(x, y, train_size=0.15, random_state=42)\n",
        "\n",
        "    dt = DecisionTreeRegressor(random_state=seed)\n",
        "\n",
        "    # CV if random search\n",
        "    if cv_type == 'random':\n",
        "        cv = RandomizedSearchCV(dt, params_to_tune, n_iter=n_random_test, random_state=0, scoring='neg_mean_absolute_percentage_error', verbose=2)\n",
        "        result = cv.fit(x_cv, y_cv)\n",
        "        print(result.best_params_)\n",
        "        return result.best_params_\n",
        "    # CV if grid search\n",
        "    if cv_type == 'gridsearch':\n",
        "        cv = GridSearchCV(dt, params_to_tune, scoring='neg_mean_absolute_percentage_error')\n",
        "        result = cv.fit(x_cv, y_cv)\n",
        "        print(result.best_params_)\n",
        "        return result.best_params_\n",
        "\n",
        "    print(\"Argument cv_type was incorrect, default parameters are returned\")\n",
        "    return {'max_depth' : 10, 'max_features' : None, 'min_samples_leaf' : 1}\n",
        "\n",
        "\n",
        "def decision_tree(x_train, y_train, x_test, cross_validation = True, cv_type='random', n_random_test=15):\n",
        "    if cross_validation:\n",
        "        params = cross_validation_decision_tree(x_train, y_train, cv_type, n_random_test)\n",
        "    else:\n",
        "        # corresponds to default values except for max_depth (pruning) to avoid to much overfitting\n",
        "        params = {'max_depth' : 100,\n",
        "                  'max_features' : None,\n",
        "                  'min_samples_leaf' : 1\n",
        "                  }\n",
        "    dt = DecisionTreeRegressor(max_depth=params['max_depth'], max_features=params['max_features'],\n",
        "                                min_samples_leaf=params['min_samples_leaf'], random_state=seed)\n",
        "    dt.fit(x_train, y_train)\n",
        "    return dt.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRg69dqotdmP",
        "outputId": "7cd257d3-4958-46b6-b8ba-4ccec954d81e"
      },
      "source": [
        "x_train_train, x_train_test, y_train_train, y_train_test = train_test_split(x_train, y_train, train_size=0.75, random_state=42)\n",
        "\n",
        "y_predict = decision_tree(x_train_train, y_train_train, x_train_test, cross_validation=True, cv_type='gridsearch')\n",
        "\n",
        "print(y_train_test)\n",
        "print(y_predict)\n",
        "\n",
        "print(mean_absolute_percentage_error(y_true=y_train_test, y_pred=y_predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "80 fits failed out of a total of 400.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "80 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 1320, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 308, in fit\n",
            "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
            "ValueError: max_features must be in (0, n_features]\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [-2.70222987e+15 -2.67883354e+15 -2.70216309e+15 -2.73926835e+15\n",
            " -2.68856640e+15 -2.69206621e+15 -2.69624752e+15 -2.70487516e+15\n",
            " -2.68118779e+15 -2.68832876e+15 -2.69832761e+15 -2.71042503e+15\n",
            " -2.67752608e+15 -2.68082400e+15 -2.69433371e+15 -2.70838739e+15\n",
            "             nan             nan             nan             nan\n",
            " -2.54484627e+15 -2.63834628e+15 -2.69898157e+15 -2.72291699e+15\n",
            " -2.56759650e+15 -2.60113123e+15 -2.67914982e+15 -2.71044962e+15\n",
            " -2.51098812e+15 -2.60357566e+15 -2.66249791e+15 -2.70476423e+15\n",
            " -2.52874293e+15 -2.58815629e+15 -2.66999165e+15 -2.70336751e+15\n",
            "             nan             nan             nan             nan\n",
            " -2.46120278e+15 -2.59805762e+15 -2.69898157e+15 -2.72291699e+15\n",
            " -2.47604841e+15 -2.58312193e+15 -2.67914982e+15 -2.71044962e+15\n",
            " -2.46208073e+15 -2.59829469e+15 -2.66249791e+15 -2.70476423e+15\n",
            " -2.41418430e+15 -2.58736068e+15 -2.66999165e+15 -2.70336751e+15\n",
            "             nan             nan             nan             nan\n",
            " -2.50537927e+15 -2.59805762e+15 -2.69898157e+15 -2.72291699e+15\n",
            " -2.49925842e+15 -2.58312193e+15 -2.67914982e+15 -2.71044962e+15\n",
            " -2.46431636e+15 -2.59829469e+15 -2.66249791e+15 -2.70476423e+15\n",
            " -2.40817197e+15 -2.58736068e+15 -2.66999165e+15 -2.70336751e+15\n",
            "             nan             nan             nan             nan]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'max_depth': 50, 'max_features': 10, 'min_samples_leaf': 10}\n",
            "20017     0.2\n",
            "127292    0.0\n",
            "15827     0.0\n",
            "83173     8.5\n",
            "117058    1.8\n",
            "         ... \n",
            "32680     3.2\n",
            "2934      2.4\n",
            "9965      0.2\n",
            "46704     0.0\n",
            "56427     0.0\n",
            "Name: ground_truth, Length: 43094, dtype: float64\n",
            "[0.84615385 1.2        0.43333333 ... 1.09090909 2.70909091 1.68125   ]\n",
            "1976667417824640.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAOPWJs8GlCa",
        "outputId": "aac0ac0a-088a-4816-9f3a-33ea523e8593"
      },
      "source": [
        "y_predict = decision_tree(x_train, y_train, x_test, cross_validation=True, cv_type='gridsearch')\n",
        "# print(mean_absolute_percentage_error(y_true=y_test, y_pred=y_predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "80 fits failed out of a total of 400.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "80 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 1320, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 308, in fit\n",
            "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
            "ValueError: max_features must be in (0, n_features]\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [-2.81169918e+15 -2.80373070e+15 -2.84075843e+15 -2.84910674e+15\n",
            " -2.78879055e+15 -2.80561421e+15 -2.82518328e+15 -2.81991035e+15\n",
            " -2.78873787e+15 -2.78163485e+15 -2.82396542e+15 -2.82624530e+15\n",
            " -2.78314671e+15 -2.79425788e+15 -2.81185006e+15 -2.82576544e+15\n",
            "             nan             nan             nan             nan\n",
            " -2.65659802e+15 -2.70012134e+15 -2.82537362e+15 -2.82297918e+15\n",
            " -2.65791533e+15 -2.69350126e+15 -2.78785855e+15 -2.81372714e+15\n",
            " -2.61686519e+15 -2.69282437e+15 -2.76278716e+15 -2.83181770e+15\n",
            " -2.58486375e+15 -2.68622735e+15 -2.78475863e+15 -2.81392826e+15\n",
            "             nan             nan             nan             nan\n",
            " -2.49340169e+15 -2.68626057e+15 -2.81776280e+15 -2.82297918e+15\n",
            " -2.47522285e+15 -2.68958446e+15 -2.78785855e+15 -2.81372714e+15\n",
            " -2.49799705e+15 -2.67959448e+15 -2.76387603e+15 -2.83181770e+15\n",
            " -2.50727350e+15 -2.67535075e+15 -2.78462535e+15 -2.81392826e+15\n",
            "             nan             nan             nan             nan\n",
            " -2.50706872e+15 -2.68626057e+15 -2.81776280e+15 -2.82297918e+15\n",
            " -2.48151405e+15 -2.68958446e+15 -2.78785855e+15 -2.81372714e+15\n",
            " -2.50130377e+15 -2.67959448e+15 -2.76387603e+15 -2.83181770e+15\n",
            " -2.50121800e+15 -2.67535075e+15 -2.78462535e+15 -2.81392826e+15\n",
            "             nan             nan             nan             nan]\n",
            "  category=UserWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9RTe-p3Y3a7",
        "outputId": "5269c0e0-2a28-416c-cae1-fa7466657cab"
      },
      "source": [
        "dataframe = pd.DataFrame()\n",
        "dataframe['Id'] = test_ids \n",
        "print(y_predict)\n",
        "dataframe['Prediction'] = y_predict + 1\n",
        "print(dataframe['Prediction'])\n",
        "\n",
        "dataframe.to_csv('submission_dt2.csv', index = False, header=True)\n",
        "print(dataframe[dataframe[\"Id\"]==\"14066001_149\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[16.75        0.84        1.32222222 ...  0.72330383  1.54666667\n",
            "  0.29333333]\n",
            "0        17.750000\n",
            "1         1.840000\n",
            "2         2.322222\n",
            "3         3.480000\n",
            "4        12.018182\n",
            "           ...    \n",
            "96050     1.083887\n",
            "96051     1.670000\n",
            "96052     1.723304\n",
            "96053     2.546667\n",
            "96054     1.293333\n",
            "Name: Prediction, Length: 96055, dtype: float64\n",
            "              Id  Prediction\n",
            "66  14066001_149       10.43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwoMX0UkgFcP"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYzqVYUbgOUy"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "\n",
        "import numpy as np\n",
        "seed = 1998\n",
        "\n",
        "def cross_validation_random_forest(x, y, cv_type, n_random_test=10):\n",
        "    \"\"\"\n",
        "    :param x_train:\n",
        "    :param y_train:\n",
        "    :param cv_type: must be 'random' or 'gridsearch'\n",
        "    :param n_random_test: nombre de jeux de paramètres à tester\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    params_to_tune = {'n_estimators': [50, 100, 200],\n",
        "                      'max_depth' : [5, 10, 20, 50],\n",
        "                      'max_features' : [4, 6, 8, 10, np.sqrt(x.shape[1])],\n",
        "                      'min_samples_leaf' : [10, 100, 500, 1000]\n",
        "                      }\n",
        "    # split the dataset by keeping 10% of the dataset for train and 5% for testing during the CV\n",
        "    rf = RandomForestRegressor(random_state=seed)\n",
        "\n",
        "    # CV if random search\n",
        "    if cv_type == 'random':\n",
        "        cv = RandomizedSearchCV(rf, params_to_tune, n_iter=n_random_test, random_state=0, scoring='neg_mean_absolute_percentage_error', verbose=2)\n",
        "        result = cv.fit(x, y)\n",
        "        print(result.best_params_)\n",
        "        return result.best_params_\n",
        "    # CV if grid search\n",
        "    if cv_type == 'gridsearch':\n",
        "        cv = GridSearchCV(rf, params_to_tune, scoring='neg_mean_absolute_percentage_error', verbose=2)\n",
        "        result = cv.fit(x, y)\n",
        "        print(result.best_params_)\n",
        "        return result.best_params_\n",
        "\n",
        "    print(\"Argument cv_type was incorrect, default parameters are returned\")\n",
        "    return {'n_estimators':100, 'max_depth' : 50, 'max_features' : None, 'min_samples_leaf' : 1}\n",
        "\n",
        "def random_forest(x_train, y_train, x_test, cross_validation = True, cv_type='random', n_random_test=15):\n",
        "    if cross_validation:\n",
        "        params = cross_validation_random_forest(x_train, y_train, cv_type, n_random_test)\n",
        "    else:\n",
        "        # corresponds to default values except for max_depth (pruning) to avoid to much overfitting\n",
        "        params = {'n_estimators':100,\n",
        "                  'max_depth' : 50,\n",
        "                  'max_features' : None,\n",
        "                  'min_samples_leaf' : 1\n",
        "                  }\n",
        "    dt = RandomForestRegressor(n_estimators=params['n_estimators'], max_depth=params['max_depth'], max_features=params['max_features'],\n",
        "                               min_samples_leaf=params['min_samples_leaf'], random_state=seed)\n",
        "    dt.fit(x_train, y_train)\n",
        "    return dt.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x64FWVWmvhL7",
        "outputId": "0d8a2c20-5298-4a19-a8d5-969de204f5cf"
      },
      "source": [
        "y_predict = random_forest(x_train, y_train, x_test, cross_validation=True, cv_type='random', n_random_test=15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
            "[CV] END max_depth=10, max_features=3.1622776601683795, min_samples_leaf=10, n_estimators=100; total time=   0.1s\n",
            "[CV] END max_depth=10, max_features=3.1622776601683795, min_samples_leaf=10, n_estimators=100; total time=   0.1s\n",
            "[CV] END max_depth=10, max_features=3.1622776601683795, min_samples_leaf=10, n_estimators=100; total time=   0.1s\n",
            "[CV] END max_depth=10, max_features=3.1622776601683795, min_samples_leaf=10, n_estimators=100; total time=   0.1s\n",
            "[CV] END max_depth=10, max_features=3.1622776601683795, min_samples_leaf=10, n_estimators=100; total time=   0.1s\n",
            "[CV] END max_depth=10, max_features=4, min_samples_leaf=1000, n_estimators=200; total time=  50.6s\n",
            "[CV] END max_depth=10, max_features=4, min_samples_leaf=1000, n_estimators=200; total time=  51.2s\n",
            "[CV] END max_depth=10, max_features=4, min_samples_leaf=1000, n_estimators=200; total time=  50.1s\n",
            "[CV] END max_depth=10, max_features=4, min_samples_leaf=1000, n_estimators=200; total time=  52.2s\n",
            "[CV] END max_depth=10, max_features=4, min_samples_leaf=1000, n_estimators=200; total time=  51.9s\n",
            "[CV] END max_depth=5, max_features=10, min_samples_leaf=10, n_estimators=100; total time=  44.1s\n",
            "[CV] END max_depth=5, max_features=10, min_samples_leaf=10, n_estimators=100; total time=  44.8s\n",
            "[CV] END max_depth=5, max_features=10, min_samples_leaf=10, n_estimators=100; total time=  44.0s\n",
            "[CV] END max_depth=5, max_features=10, min_samples_leaf=10, n_estimators=100; total time=  43.9s\n",
            "[CV] END max_depth=5, max_features=10, min_samples_leaf=10, n_estimators=100; total time=  44.5s\n",
            "[CV] END max_depth=10, max_features=6, min_samples_leaf=10, n_estimators=200; total time= 1.7min\n",
            "[CV] END max_depth=10, max_features=6, min_samples_leaf=10, n_estimators=200; total time= 1.6min\n",
            "[CV] END max_depth=10, max_features=6, min_samples_leaf=10, n_estimators=200; total time= 1.6min\n",
            "[CV] END max_depth=10, max_features=6, min_samples_leaf=10, n_estimators=200; total time= 1.6min\n",
            "[CV] END max_depth=10, max_features=6, min_samples_leaf=10, n_estimators=200; total time= 1.6min\n",
            "[CV] END max_depth=10, max_features=3.1622776601683795, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=3.1622776601683795, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=3.1622776601683795, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=3.1622776601683795, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=3.1622776601683795, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
            "[CV] END max_depth=50, max_features=10, min_samples_leaf=1000, n_estimators=200; total time= 2.0min\n",
            "[CV] END max_depth=50, max_features=10, min_samples_leaf=1000, n_estimators=200; total time= 2.0min\n",
            "[CV] END max_depth=50, max_features=10, min_samples_leaf=1000, n_estimators=200; total time= 2.0min\n",
            "[CV] END max_depth=50, max_features=10, min_samples_leaf=1000, n_estimators=200; total time= 2.0min\n",
            "[CV] END max_depth=50, max_features=10, min_samples_leaf=1000, n_estimators=200; total time= 2.1min\n",
            "[CV] END max_depth=20, max_features=10, min_samples_leaf=10, n_estimators=50; total time= 1.0min\n",
            "[CV] END max_depth=20, max_features=10, min_samples_leaf=10, n_estimators=50; total time= 1.0min\n",
            "[CV] END max_depth=20, max_features=10, min_samples_leaf=10, n_estimators=50; total time= 1.0min\n",
            "[CV] END max_depth=20, max_features=10, min_samples_leaf=10, n_estimators=50; total time= 1.0min\n",
            "[CV] END max_depth=20, max_features=10, min_samples_leaf=10, n_estimators=50; total time= 1.0min\n",
            "[CV] END max_depth=50, max_features=10, min_samples_leaf=100, n_estimators=100; total time= 1.6min\n",
            "[CV] END max_depth=50, max_features=10, min_samples_leaf=100, n_estimators=100; total time= 1.6min\n",
            "[CV] END max_depth=50, max_features=10, min_samples_leaf=100, n_estimators=100; total time= 1.6min\n",
            "[CV] END max_depth=50, max_features=10, min_samples_leaf=100, n_estimators=100; total time= 1.5min\n",
            "[CV] END max_depth=50, max_features=10, min_samples_leaf=100, n_estimators=100; total time= 1.6min\n",
            "[CV] END max_depth=20, max_features=8, min_samples_leaf=500, n_estimators=200; total time= 2.0min\n",
            "[CV] END max_depth=20, max_features=8, min_samples_leaf=500, n_estimators=200; total time= 2.1min\n",
            "[CV] END max_depth=20, max_features=8, min_samples_leaf=500, n_estimators=200; total time= 1.9min\n",
            "[CV] END max_depth=20, max_features=8, min_samples_leaf=500, n_estimators=200; total time= 1.9min\n",
            "[CV] END max_depth=20, max_features=8, min_samples_leaf=500, n_estimators=200; total time= 1.9min\n",
            "[CV] END max_depth=50, max_features=6, min_samples_leaf=10, n_estimators=200; total time= 2.5min\n",
            "[CV] END max_depth=50, max_features=6, min_samples_leaf=10, n_estimators=200; total time= 2.5min\n",
            "[CV] END max_depth=50, max_features=6, min_samples_leaf=10, n_estimators=200; total time= 2.6min\n",
            "[CV] END max_depth=50, max_features=6, min_samples_leaf=10, n_estimators=200; total time= 2.6min\n",
            "[CV] END max_depth=50, max_features=6, min_samples_leaf=10, n_estimators=200; total time= 2.6min\n",
            "[CV] END max_depth=10, max_features=6, min_samples_leaf=100, n_estimators=100; total time=  47.1s\n",
            "[CV] END max_depth=10, max_features=6, min_samples_leaf=100, n_estimators=100; total time=  47.2s\n",
            "[CV] END max_depth=10, max_features=6, min_samples_leaf=100, n_estimators=100; total time=  47.8s\n",
            "[CV] END max_depth=10, max_features=6, min_samples_leaf=100, n_estimators=100; total time=  47.3s\n",
            "[CV] END max_depth=10, max_features=6, min_samples_leaf=100, n_estimators=100; total time=  48.5s\n",
            "[CV] END max_depth=50, max_features=6, min_samples_leaf=1000, n_estimators=100; total time=  37.6s\n",
            "[CV] END max_depth=50, max_features=6, min_samples_leaf=1000, n_estimators=100; total time=  37.5s\n",
            "[CV] END max_depth=50, max_features=6, min_samples_leaf=1000, n_estimators=100; total time=  38.2s\n",
            "[CV] END max_depth=50, max_features=6, min_samples_leaf=1000, n_estimators=100; total time=  38.8s\n",
            "[CV] END max_depth=50, max_features=6, min_samples_leaf=1000, n_estimators=100; total time=  38.1s\n",
            "[CV] END max_depth=10, max_features=6, min_samples_leaf=1000, n_estimators=200; total time= 1.2min\n",
            "[CV] END max_depth=10, max_features=6, min_samples_leaf=1000, n_estimators=200; total time= 1.2min\n",
            "[CV] END max_depth=10, max_features=6, min_samples_leaf=1000, n_estimators=200; total time= 1.2min\n",
            "[CV] END max_depth=10, max_features=6, min_samples_leaf=1000, n_estimators=200; total time= 1.2min\n",
            "[CV] END max_depth=10, max_features=6, min_samples_leaf=1000, n_estimators=200; total time= 1.2min\n",
            "[CV] END max_depth=20, max_features=10, min_samples_leaf=10, n_estimators=100; total time= 2.0min\n",
            "[CV] END max_depth=20, max_features=10, min_samples_leaf=10, n_estimators=100; total time= 2.0min\n",
            "[CV] END max_depth=20, max_features=10, min_samples_leaf=10, n_estimators=100; total time= 2.0min\n",
            "[CV] END max_depth=20, max_features=10, min_samples_leaf=10, n_estimators=100; total time= 2.0min\n",
            "[CV] END max_depth=20, max_features=10, min_samples_leaf=10, n_estimators=100; total time= 2.0min\n",
            "[CV] END max_depth=50, max_features=3.1622776601683795, min_samples_leaf=500, n_estimators=50; total time=   0.0s\n",
            "[CV] END max_depth=50, max_features=3.1622776601683795, min_samples_leaf=500, n_estimators=50; total time=   0.0s\n",
            "[CV] END max_depth=50, max_features=3.1622776601683795, min_samples_leaf=500, n_estimators=50; total time=   0.0s\n",
            "[CV] END max_depth=50, max_features=3.1622776601683795, min_samples_leaf=500, n_estimators=50; total time=   0.0s\n",
            "[CV] END max_depth=50, max_features=3.1622776601683795, min_samples_leaf=500, n_estimators=50; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "15 fits failed out of a total of 75.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "15 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\", line 459, in fit\n",
            "    for i, t in enumerate(trees)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 1043, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 779, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 263, in __call__\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\", line 211, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
            "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 1320, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 308, in fit\n",
            "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
            "ValueError: max_features must be in (0, n_features]\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [            nan -2.74983388e+15 -2.72851549e+15 -2.56160148e+15\n",
            "             nan -2.67190227e+15 -2.39790221e+15 -2.49672644e+15\n",
            " -2.62986924e+15 -2.41524054e+15 -2.58409026e+15 -2.70342000e+15\n",
            " -2.70560159e+15 -2.40252396e+15             nan]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_estimators': 50, 'min_samples_leaf': 10, 'max_features': 10, 'max_depth': 20}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMgNQ_BpvmAv",
        "outputId": "75277645-dc8b-4048-957f-238b040b8383"
      },
      "source": [
        "dataframe = pd.DataFrame()\n",
        "dataframe['Id'] = test_ids \n",
        "print(y_predict)\n",
        "dataframe['Prediction'] = y_predict + 1\n",
        "print(dataframe['Prediction'])\n",
        "\n",
        "dataframe.to_csv('submission_rd.csv', index = False, header=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9.87213426 2.20271821 4.46689356 ... 1.2782421  2.46053906 0.34841677]\n",
            "0        10.872134\n",
            "1         3.202718\n",
            "2         5.466894\n",
            "3         3.473030\n",
            "4        11.362482\n",
            "           ...    \n",
            "96050     1.847725\n",
            "96051     2.920088\n",
            "96052     2.278242\n",
            "96053     3.460539\n",
            "96054     1.348417\n",
            "Name: Prediction, Length: 96055, dtype: float64\n"
          ]
        }
      ]
    }
  ]
}